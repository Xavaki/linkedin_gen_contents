{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239f6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb72b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to process: 41\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../local_tests_data/relevant_articles_content/\"\n",
    "\n",
    "articles_filenames = os.listdir(data_path)\n",
    "\n",
    "n_articles_to_process = len(articles_filenames)\n",
    "\n",
    "print(f\"Number of articles to process: {n_articles_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adf9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 batch files\n"
     ]
    }
   ],
   "source": [
    "prompts_per_batch_job = 200\n",
    "n_batch_jobs = ceil(n_articles_to_process/prompts_per_batch_job)\n",
    "print(\"Creating {} batch files\".format(n_batch_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a professional content assistant summarizing articles for a LinkedIn thought leader. Summarize the article in 3 to 8 sentences. Focus on:\n",
    "\n",
    "    The main idea or thesis\n",
    "    The most important insight or data\n",
    "    Why it matters to professionals or business leaders\n",
    "\n",
    "    Use clear, neutral, and professional language. Avoid fluff or opinion.\n",
    "\n",
    "You must summarize the article in English, even if the article is in another language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d894566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_task_jsonl_line(task_id, deployment_name, user_input):\n",
    "    jsonl_line_template = {\n",
    "        \"custom_id\": task_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": deployment_name,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_input\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    return jsonl_line_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonl_lines(chunk_id, chunk_articles_filenames):\n",
    "    for j,article_filename in enumerate(chunk_articles_filenames):\n",
    "        article_id = article_filename.split(\".\")[0]\n",
    "        with open(data_path + article_filename, \"r\") as f:\n",
    "            article_content = json.load(f)[\"content\"]\n",
    "        task_id = f\"article-summarization-v0*{article_id}\"\n",
    "        deployment_name = \"gpt-4o--batch-2\"\n",
    "        yield json.dumps(format_task_jsonl_line(task_id=task_id, deployment_name=deployment_name, user_input=article_content)) + \"\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ea39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_batch_jobs):\n",
    "    print(i)\n",
    "    chunk = articles_filenames[i*prompts_per_batch_job:min(n_articles_to_process, (i+1)*prompts_per_batch_job)]\n",
    "    batchfilename = f\"article-summarization-v0_{i}_BATCHFILE.jsonl\"\n",
    "    with open(batchfilename, \"w\") as f:\n",
    "        for line in generate_jsonl_lines(chunk_id=i, chunk_articles_filenames=chunk):\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a507bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
