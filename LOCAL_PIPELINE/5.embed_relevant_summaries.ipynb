{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11912231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "import pandas as pd\n",
<<<<<<< HEAD
    "from dotenv import load_dotenv"
=======
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
<<<<<<< HEAD:5.embed_relevant_summaries.ipynb
    "from datetime import datetime"
>>>>>>> 8b6afdb (runid 2 completed (local))
=======
    "from datetime import datetime\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient"
>>>>>>> 80830b3 (cloud pipeline with nbs working):LOCAL_PIPELINE/5.embed_relevant_summaries.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
   "id": "7d3d1222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: RUNID_1 at 2025-06-02 16:09:03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_run_id():\n",
    "    return os.getenv('RUNID') \n",
    "\n",
    "RUNID = get_run_id()\n",
    "\n",
    "\n",
    "RUN_TIME = datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "INPUT_DATA_PATH = f\"./local_tests_data/relevant_articles_summaries/{RUNID}/relevant_articles_summaries_{RUNID}.json\"\n",
    "OUTPUT_DATA_PATH = f\"./local_tests_data/relevant_articles_summaries_embeddings/{RUNID}/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DATA_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Run ID: {RUNID} at {RUN_TIME}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:5.embed_relevant_summaries.ipynb
   "execution_count": 4,
>>>>>>> 8b6afdb (runid 2 completed (local))
=======
   "execution_count": 45,
>>>>>>> 80830b3 (cloud pipeline with nbs working):LOCAL_PIPELINE/5.embed_relevant_summaries.ipynb
   "id": "e43c2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "load_dotenv('.env')\n",
=======
>>>>>>> 8b6afdb (runid 2 completed (local))
    "AZURE_OPENAI_API_KEY=os.getenv('AZURE_OPENAI_API_KEY')\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5da845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summaries_to_embed():\n",
    "    summaries = []\n",
    "    with open(INPUT_DATA_PATH, 'r') as f:\n",
    "        summaries = json.load(f)\n",
    "            \n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8d3e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = get_summaries_to_embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edb79b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries to embed: 22\n"
     ]
    }
   ],
   "source": [
    "n_summaries_to_embed = len(summaries)\n",
    "print(f\"Number of summaries to embed: {n_summaries_to_embed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57632fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35f05866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-4o-2024-11-20',\n",
       " 'summary': \"A recent report from cybersecurity firm Netskope revealed that 25% of European organizations have banned Elon Musk's generative AI chatbot, Grok, citing concerns over security, privacy, and accuracy. Grok's missteps, including spreading misinformation about sensitive topics, have led businesses to favor alternatives like ChatGPT, which is only blocked by 9.8% of organizations. The research highlights a broader trend where professionals are prioritizing data security, privacy, and ethical considerations when adopting generative AI tools.\\n\\nNeil Thacker, Netskope's global privacy officer, emphasized the importance of understanding data ownership and transparency in AI models, as businesses integrate such tools in 91% of operations. Other AI apps, such as Stability AI's Stable Diffusion, face even higher rejection rates due to licensing and privacy concerns. This report underscores the increasing demand for secure and reliable AI solutions, offering key insights for leaders navigating technology adoption in their industries.\",\n",
       " 'article_id': 'the_next_web_20250530144751581654',\n",
       " 'run_id': 'RUNID_1',\n",
       " 'task_name': 'article_summarization_v0'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b454c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_summaries = [[]]\n",
    "\n",
    "running_token_count = 0\n",
    "\n",
    "for summary_obj in summaries:\n",
    "\n",
    "    article_id = summary_obj['article_id']\n",
    "    summary = summary_obj['summary']\n",
    " \n",
    "    tokens = encoding.encode(summary)\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    running_token_count += token_count\n",
    "    if running_token_count > 8000: # true limit is 8192, but we leave some space for safety\n",
    "        chunked_summaries.append([])\n",
    "        running_token_count = 0\n",
    "    \n",
    "    chunked_summaries[-1].append({\"summary\" : summary, \"article_id\": article_id, \"token_count\": token_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff97d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding chunk 0 of 1 with 22 summaries\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "\n",
    "for i,chunk in enumerate(chunked_summaries):\n",
    "    print(f\"embedding chunk {i} of {len(chunked_summaries)} with {len(chunk)} summaries\")\n",
    "    chunk_article_ids = [s.get(\"article_id\") for s in chunk]\n",
    "\n",
    "    embedding_model = \"text-embedding-3-small\"\n",
    "    response = client.embeddings.create(\n",
    "        input=[s.get(\"summary\") for s in chunk],\n",
    "        model=embedding_model,\n",
    "    )\n",
    "\n",
    "    for article_id, item in zip(chunk_article_ids, response.data):\n",
    "        all_embeddings.append({\n",
    "            'article_id': article_id,\n",
    "            'summary_embedding': item.embedding,\n",
    "            'embedding_model': embedding_model,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81c5b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>summary_embedding</th>\n",
       "      <th>embedding_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_next_web_20250530144751581654</td>\n",
       "      <td>[-0.009674579836428165, 0.006264630705118179, ...</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itespresso_20250530144751622699</td>\n",
       "      <td>[0.011496803723275661, 0.06475908309221268, 0....</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_next_web_20250530144751551046</td>\n",
       "      <td>[-0.007235630415380001, -0.013063831254839897,...</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_insider_20250530144751673882</td>\n",
       "      <td>[0.022377390414476395, -0.007725527510046959, ...</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itespresso_20250530144751612511</td>\n",
       "      <td>[0.007954786531627178, -0.029804697260260582, ...</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              article_id  \\\n",
       "0      the_next_web_20250530144751581654   \n",
       "1        itespresso_20250530144751622699   \n",
       "2      the_next_web_20250530144751551046   \n",
       "3  business_insider_20250530144751673882   \n",
       "4        itespresso_20250530144751612511   \n",
       "\n",
       "                                   summary_embedding         embedding_model  \n",
       "0  [-0.009674579836428165, 0.006264630705118179, ...  text-embedding-3-small  \n",
       "1  [0.011496803723275661, 0.06475908309221268, 0....  text-embedding-3-small  \n",
       "2  [-0.007235630415380001, -0.013063831254839897,...  text-embedding-3-small  \n",
       "3  [0.022377390414476395, -0.007725527510046959, ...  text-embedding-3-small  \n",
       "4  [0.007954786531627178, -0.029804697260260582, ...  text-embedding-3-small  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_embeddings = pd.DataFrame(all_embeddings) \n",
    "pd_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "471e9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings():\n",
    "    with open(OUTPUT_DATA_PATH + f\"relevant_articles_summaries_embeddings_{RUNID}.json\", 'w') as f:\n",
    "        json.dump(all_embeddings, f, indent=4)\n",
    "    print(f\"Embeddings saved to {OUTPUT_DATA_PATH}relevant_articles_summaries_embeddings_{RUNID}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cd72c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to ./local_tests_data/relevant_articles_summaries_embeddings/RUNID_1/relevant_articles_summaries_embeddings_RUNID_1.json\n"
     ]
    }
   ],
   "source": [
    "save_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215e5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
