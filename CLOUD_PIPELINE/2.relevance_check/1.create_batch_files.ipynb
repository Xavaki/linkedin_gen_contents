{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "239f6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1af4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca5f792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: RUNID_3 at 2025-06-03 14:24:08\n"
     ]
    }
   ],
   "source": [
    "TASK_NAME = \"relevance_check_v0\"\n",
    "DEPLOYMENT_NAME = \"gpt-4o--batch-2\"\n",
    "\n",
    "def get_run_id():\n",
    "    return os.getenv('RUNID')\n",
    "\n",
    "\n",
    "RUNID = get_run_id()\n",
    "\n",
    "RUN_TIME = datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(os.getenv('STORAGE_ACCOUNT_CONNECTION_STRING'))\n",
    "\n",
    "input_container_name = \"raw-articles-list\"\n",
    "output_container_name = \"azure-openai-batch-processing-files\"\n",
    "\n",
    "INPUT_DATA_PATH = f\"../local_tests_data/raw_articles_list/{RUNID}/raw_articles_list_{RUNID}.json\"\n",
    "OUTPUT_DATA_PATH = f\"../local_tests_data/azure_openai_batch_processing_files/{RUNID}/{TASK_NAME}/BATCHFILES/\"\n",
    "\n",
    "input_container = blob_service_client.get_container_client(input_container_name)\n",
    "assert input_container.exists(), f\"Input container '{input_container_name}' does not exist.\"\n",
    "output_container = blob_service_client.get_container_client(output_container_name)\n",
    "assert output_container.exists(), f\"Output container '{output_container_name}' does not exist.\"\n",
    "\n",
    "input_blob = input_container.get_blob_client(f\"{RUNID}--raw_articles_list.json\")\n",
    "assert input_blob.exists(), f\"Input blob '{RUNID}--source_raw_content.json' does not exist in container '{input_container_name}'.\"\n",
    "\n",
    "print(f\"Run ID: {RUNID} at {RUN_TIME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88db4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawArticle(BaseModel):\n",
    "    model: str\n",
    "    run_id: str\n",
    "    task_name: str\n",
    "    source_name: str\n",
    "    article_id: str\n",
    "    article_title: str\n",
    "    article_url: str\n",
    "    article_keywords: list[str]\n",
    "    article_language: str\n",
    "    crawled_at: str\n",
    "\n",
    "def get_raw_articles_list() -> list[RawArticle]:    \n",
    "    raw_articles_list = json.loads(input_blob.download_blob().readall().decode('utf-8'))\n",
    "    return [RawArticle(**a) for a in raw_articles_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb72b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to process: 23\n"
     ]
    }
   ],
   "source": [
    "raw_articles_list = get_raw_articles_list()\n",
    "n_to_process = len(raw_articles_list)\n",
    "print(f\"Number of articles to process: {n_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8adf9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 batch files\n"
     ]
    }
   ],
   "source": [
    "prompts_per_batch_job = 200\n",
    "n_batch_jobs = ceil(n_to_process/prompts_per_batch_job)\n",
    "print(\"Creating {} batch files\".format(n_batch_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a smart content curator for a LinkedIn thought leader. Given a news article, decide if it is highly relevant based on the following criteria:\n",
    "    - It aligns with topics like: Artificial Intelligence, Leadership, Remote Work, Digital Transformation, Sustainability, Emerging Tech, Industry Trends, Organizational Culture, DEI, Future of Work, Cybersecurity, Productivity, Startups, Market Trends, or Personal Branding.\n",
    "    - It provides useful insight, a new perspective, or credible data.\n",
    "    - It is suitable for a professional audience.\n",
    "\n",
    "You must adhere to the provided criteria and schema.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d894566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_task_jsonl_line(task_id, deployment_name, user_input):\n",
    "    jsonl_line_template = {\n",
    "        \"custom_id\": task_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": deployment_name,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt.replace(\"\\n\", \"\\\\n\")\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_input.replace(\"\\n\", \"\\\\n\")\n",
    "                }\n",
    "            ],\n",
    "            \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"ArticleRelevanceCheck\",\n",
    "                \"strict\": True,\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"relevance\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Relevance score for the article, between 0 and 2, where 0 means not relevant, 1 means somewhat relevant, and 2 means highly relevant.\",\n",
    "                            \"enum\": [0, 1, 2]\n",
    "                        },\n",
    "                        \"article_language\": {\n",
    "                            \"type\": \"string\",\n",
    "                        } \n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"relevance\",\n",
    "                        \"article_language\"\n",
    "                    ],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        }\n",
    "    }\n",
    "    return jsonl_line_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aafbcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonl_lines(chunk_id, chunk_items):\n",
    "    for j,article_info in enumerate(chunk_items):\n",
    "        article_id = article_info.article_id\n",
    "        task_id = f\"{RUNID}--{TASK_NAME}--{article_id}\"\n",
    "        deployment_name = DEPLOYMENT_NAME\n",
    "        a = {\n",
    "            \"article_title\" : article_info.article_title,\n",
    "            \"article_url\" : article_info.article_url,\n",
    "            \"article_keywords\" : article_info.article_keywords,\n",
    "            \"article_language\" : article_info.article_language,\n",
    "        }\n",
    "        yield json.dumps(format_task_jsonl_line(task_id=task_id, deployment_name=deployment_name, user_input=json.dumps(a))) + \"\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18ea39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Batch file RUNID_3--relevance_check_v0_BATCHFILE_0.jsonl created with 23 tasks.\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_batch_jobs):\n",
    "    print(i)\n",
    "    chunk = raw_articles_list[i*prompts_per_batch_job:min(n_to_process, (i+1)*prompts_per_batch_job)]\n",
    "    batchfilename = f\"{RUNID}--{TASK_NAME}_BATCHFILE_{i}.jsonl\"\n",
    "\n",
    "    batchfile_blob  = output_container.get_blob_client(batchfilename)\n",
    "    batchfile_blob.upload_blob(generate_jsonl_lines(chunk_id=i, chunk_items=chunk), overwrite=True, encoding='utf-8')\n",
    "    print(f\"Batch file {batchfilename} created with {len(chunk)} tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a507bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
