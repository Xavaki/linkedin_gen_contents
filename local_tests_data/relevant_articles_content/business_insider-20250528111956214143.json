{
    "content": "Estamos finalmente comenzando a atisbar c\u00f3mo ser\u00e1 Google cuando est\u00e9 completamente transformado por la inteligencia artificial (IA).\n\nLa conferencia I/O del a\u00f1o pasado trajo una avalancha de anuncios relacionados con la IA y una sensaci\u00f3n de que el gigante de las b\u00fasquedas estaba intentando demostrar que a\u00fan ten\u00eda la capacidad para liderar esta carrera, con una gran cantidad de productos y demostraciones diversos.\n\nEste a\u00f1o, se est\u00e1 perfilando una imagen m\u00e1s clara de c\u00f3mo Google ve el futuro de sus productos principales, incluyendo lo que el CEO Sundar Pichai llam\u00f3 una \"reimaginaci\u00f3n total\" de b\u00fasquedas durante una mesa redonda con la prensa antes del evento. Esto incluye una b\u00fasqueda m\u00e1s conversacional llamada Modo IA y, finalmente, un asistente de IA que entiende el mundo que te rodea.\n\nGoogle se ha enfrentado a un gran dilema: la publicidad en b\u00fasquedas genera la mayor parte de los ingresos multimillonarios de la empresa, aunque sabe que no puede quedarse quieto y permitir que sus rivales le roben cuota de mercado. Est\u00e1 intentando incorporar la IA en su producto principal antes de que alguien m\u00e1s lo haga mejor. Pero no tan r\u00e1pido como para poner en riesgo la maquinaria de beneficios de la empresa.\n\nLa compa\u00f1\u00eda ha estado avanzando lentamente con Res\u00famenes de IA, y esta semana est\u00e1 lanzando su Modo IA para todos. Mientras que los Res\u00famenes de IA ofrecen un resumen de la respuesta en la parte superior de la p\u00e1gina de b\u00fasqueda normal, el Modo IA permite a los usuarios hacer clic en una nueva pesta\u00f1a, que abre una experiencia conversacional que presenta una variedad m\u00e1s diversa de fuentes, todas a\u00fan basadas en el \u00edndice de b\u00fasqueda de Google. Los usuarios tambi\u00e9n pueden hacer preguntas de seguimiento.\n\n\"El Modo IA no es solo esta experiencia impulsada por IA de principio a fin, sino que tambi\u00e9n es un vistazo a lo que est\u00e1 por venir en la b\u00fasqueda en general\", explic\u00f3 Liz Reid, jefa de Google Search.\n\nEl Modo IA utiliza lo que Google denomina una t\u00e9cnica de \"dispersi\u00f3n de consultas\", lo que significa que ejecuta m\u00faltiples consultas simult\u00e1neamente y devuelve los resultados todos a la vez. Google asegura que mejorar\u00e1 las b\u00fasquedas y permitir\u00e1 que los usuarios hagan preguntas m\u00e1s complejas.\n\nLa funci\u00f3n actual es solo el comienzo de c\u00f3mo Google ve la evoluci\u00f3n de la b\u00fasqueda. Google est\u00e1 anunciando un conjunto de nuevas herramientas que por ahora mantendr\u00e1 en Labs, por lo que solo estar\u00e1n disponibles para los primeros probadores. Aun as\u00ed, muestran lo que Google considera el futuro de la b\u00fasqueda.\n\nUn ejemplo es la b\u00fasqueda profunda o Deep Search, que permite a los usuarios introducir una pregunta extremadamente larga y complicada y devuelve un informe totalmente citado, muy parecido a la funci\u00f3n de Investigaci\u00f3n Profunda de Google en Gemini. Tambi\u00e9n hay una versi\u00f3n que devuelve datos y visualizaciones en tiempo real (por ejemplo, gr\u00e1ficos sobre las estad\u00edsticas de los equipos deportivos).\n\nNi ChatGPT ni Gemini: la IA de una startup espa\u00f1ola que te ahorrar\u00e1 mucho tiempo\n\nGoogle tambi\u00e9n permitir\u00e1 a los usuarios dar acceso al Modo IA a otras aplicaciones de Google y su historial de b\u00fasqueda para que pueda devolver respuestas y recomendaciones m\u00e1s personalizadas.\n\nReid indic\u00f3 que Google incorporar\u00eda algunas de las caracter\u00edsticas del Modo IA en su motor de b\u00fasqueda est\u00e1ndar y en los Res\u00famenes de IA, con la idea de que la experiencia de b\u00fasqueda est\u00e1ndar de Google se beneficie de los avances que est\u00e1 realizando en los modelos subyacentes de IA.\n\n\"Si sumas todo esto, realmente se est\u00e1 construyendo el futuro de la b\u00fasqueda\", se\u00f1al\u00f3 Reid. \"Buscar empieza a parecer f\u00e1cil\".\n\n\u00bfSe imagina Google que el Modo IA sea el predeterminado alg\u00fan d\u00eda? Eso es lo que se deduce de esto, aunque la empresa vigilar\u00e1 de cerca durante los pr\u00f3ximos meses para ver cu\u00e1nta gente hace clic en la pesta\u00f1a Modo IA.\n\nEl asistente integral\n\nGoogle tambi\u00e9n tiene una visi\u00f3n de un asistente de IA que est\u00e9 contigo todo el tiempo.\n\nSi has visto el Proyecto Astra de Google, un agente de IA que utiliza visi\u00f3n para ver el mundo que le rodea, ya tienes una buena idea de lo que Google est\u00e1 pensando aqu\u00ed. Quiere construir un asistente que te acompa\u00f1e en cualquier lugar, ya sea en tu m\u00f3vil o en unas gafas de realidad aumentada, y que pueda ver el mundo, responder preguntas y comunicarte informaci\u00f3n en cuesti\u00f3n de segundos. O quiz\u00e1s simplemente te est\u00e9 ayudando a codificar.\n\nEn I/O, Google anunci\u00f3 que est\u00e1 ampliando su modelo Gemini 2.5 Pro para que sea un \"modelo del mundo\", lo que realmente significa que podr\u00e1 entender lo que est\u00e1 viendo y, seg\u00fan Google, hacer planes. En t\u00e9rminos de inteligencia artificial, se est\u00e1 convirtiendo en un agente.\n\nDemis Hassabis, CEO de Google DeepMind, afirm\u00f3 que estas actualizaciones son \"pasos cr\u00edticos\" para construir un \"asistente de IA universal\" que pueda entender mejor al usuario y tomar decisiones en su nombre.\n\n\"Este es nuestro objetivo final para la aplicaci\u00f3n Gemini: una IA que sea personal, proactiva y potente\", a\u00f1adi\u00f3 Hassabis.\n\nGoogle tiene previsto hacer disponible para todos su Gemini Live, habilitado para c\u00e1maras y con posibilidad de compartir pantalla, junto con el lanzamiento de Veo 3, un modelo de generaci\u00f3n de v\u00eddeo que incluye soporte para combinar efectos de sonido.\n\nPara ello, tiene que actuar con rapidez. Aunque la IA generativa a\u00fan no es un negocio cr\u00edtico como lo es la b\u00fasqueda, la empresa afirm\u00f3 que su aplicaci\u00f3n Gemini ten\u00eda m\u00e1s de 400 millones de usuarios activos mensuales. El propio an\u00e1lisis interno de Google revel\u00f3 que Gemini segu\u00eda por detr\u00e1s de las aplicaciones de OpenAI y Meta a principios de este a\u00f1o, seg\u00fan los documentos mostrados en los tribunales.\n\nConoce c\u00f3mo trabajamos en BusinessInsider .\n\nEtiquetas: Trending, Inteligencia artificial, Tecnolog\u00eda, Google, OpenAI",
    "title": "As\u00ed ser\u00e1 Google cuando la IA est\u00e9 en todas partes",
    "publish_date": "2025-05-21"
}